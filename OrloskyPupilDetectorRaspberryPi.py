import cv2
import numpy as np
import time

# Crop the image to maintain a specific aspect ratio (width:height) before resizing.
def crop_to_aspect_ratio(image, width=640, height=480):
    current_height, current_width = image.shape[:2]
    desired_ratio = width / height
    current_ratio = current_width / current_height

    if current_ratio > desired_ratio:
        # Current image is too wide
        new_width = int(desired_ratio * current_height)
        offset = (current_width - new_width) // 2
        cropped_img = image[:, offset:offset + new_width]
    else:
        # Current image is too tall
        new_height = int(current_width / desired_ratio)
        offset = (current_height - new_height) // 2
        cropped_img = image[offset:offset + new_height, :]

    return cv2.resize(cropped_img, (width, height))
    
# Apply thresholding to an image
def apply_binary_threshold(image, darkestPixelValue, addedThreshold):
    threshold = darkestPixelValue + addedThreshold
    _, thresholded_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY_INV)
    return thresholded_image

# Finds a square area of dark pixels in the image
def get_darkest_area(gray):
    ignoreBounds = 20
    imageSkipSize = 20
    searchArea = 20
    internalSkipSize = 10

    min_sum = float('inf')
    darkest_point = None

    max_x = gray.shape[1] - max(ignoreBounds, searchArea)
    skipRatio = searchArea // internalSkipSize
    for y in range(ignoreBounds, gray.shape[0] - max(ignoreBounds, searchArea), imageSkipSize):
        current_sum = np.zeros((gray.shape[1] - (ignoreBounds + max(ignoreBounds, searchArea))) // searchArea * skipRatio)
        for dy in range(0, searchArea, internalSkipSize):
            current_sum += gray[y + dy][ignoreBounds:max_x:internalSkipSize]
        current_sum = np.convolve(current_sum, np.ones(skipRatio), 'valid')[::skipRatio]
        dx = np.argmin(current_sum)
        if current_sum[dx] < min_sum:
            min_sum = current_sum[dx]
            darkest_point = (dx * searchArea + ignoreBounds + searchArea // 2, y + searchArea // 2)
    return darkest_point
    
# Mask all pixels outside a square defined by center and size
def mask_outside_square(image, center, size):
    x, y = center
    half_size = size // 2

    mask = np.zeros_like(image)
    top_left_x = max(0, x - half_size)
    top_left_y = max(0, y - half_size)
    bottom_right_x = min(image.shape[1], x + half_size)
    bottom_right_y = min(image.shape[0], y + half_size)
    mask[top_left_y:bottom_right_y, top_left_x:top_left_x + size] = 255
    return cv2.bitwise_and(image, mask)
    
# Returns the largest contour that is not extremely long or tall
def filter_contours_by_area_and_return_largest(contours, pixel_thresh, ratio_thresh):
    max_area = 0
    largest_contour = None

    for contour in contours:
        area = cv2.contourArea(contour)
        if area >= pixel_thresh:
            x, y, w, h = cv2.boundingRect(contour)
            length_to_width_ratio = max(w / h, h / w)
            if length_to_width_ratio <= ratio_thresh:
                if area > max_area:
                    max_area = area
                    largest_contour = contour

    return [largest_contour] if largest_contour is not None else []

# Process frames for pupil detection
def process_frames(thresholded_image_medium, frame, gray_frame, darkest_point, debug_mode_on, render_cv_window):
    kernel_size = 5
    kernel = np.ones((kernel_size, kernel_size), np.uint8)

    dilated_image = cv2.dilate(thresholded_image_medium, kernel, iterations=2)
    contours, _ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    reduced_contours = filter_contours_by_area_and_return_largest(contours, 1000, 3)

    final_rotated_rect = ((0, 0), (0, 0), 0)
    if len(reduced_contours) > 0 and len(reduced_contours[0]) > 5:
        ellipse = cv2.fitEllipse(reduced_contours[0])
        cv2.ellipse(frame, ellipse, (0, 255, 0), 2)
        center_x, center_y = map(int, ellipse[0])
        cv2.circle(frame, (center_x, center_y), 3, (255, 255, 0), -1)
        final_rotated_rect = ellipse

    # Calculate FPS
    current_time = time.time()
    fps = int(1 / (current_time - process_frames.last_time)) if hasattr(process_frames, "last_time") else 0
    process_frames.last_time = current_time

    # Display FPS on the frame
    cv2.putText(frame, f"FPS: {fps}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    frame = cv2.resize(frame, (320, 240))
    cv2.imshow("Frame with Ellipse", frame)

    if render_cv_window:
        cv2.imshow("Best Thresholded Image Contours on Frame", frame)

    return final_rotated_rect
    
# Process a single frame for pupil detection
def process_frame(frame):
    start_time = time.time()
    
    frame = crop_to_aspect_ratio(frame)
    firstTime = time.time() - start_time
    #print(f"Time after crop_to_aspect_ratio: {time.time() - start_time:.6f} seconds")

    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    secondTime = time.time() - start_time
    #print(f"Time after cvtColor to gray: {time.time() - start_time:.6f} seconds")
    
    darkest_point = get_darkest_area(gray_frame)
    thirdTime = time.time() - start_time
    #print(f"Time after get_darkest_area: {time.time() - start_time:.6f} seconds")
    
    darkest_pixel_value = gray_frame[darkest_point[1], darkest_point[0]]
    thresholded_image_medium = apply_binary_threshold(gray_frame, darkest_pixel_value, 15)
    fourthTime = time.time() - start_time
    #print(f"Time after apply_binary_threshold: {time.time() - start_time:.6f} seconds")
    
    thresholded_image_medium = mask_outside_square(thresholded_image_medium, darkest_point, 250)
    fifthTime = time.time() - start_time
    #print(f"Time after mask_outside_square: {time.time() - start_time:.6f} seconds")
    
    result = process_frames(thresholded_image_medium, frame, gray_frame, darkest_point, False, False)
    endTime = time.time() - start_time
    #print(f"Time after process_frames: {time.time() - start_time:.6f} seconds")
    
    return result, firstTime, secondTime, thirdTime, fourthTime, fifthTime, endTime

# Process video frames for pupil detection using OpenCV
def process_video_with_opencv():
    cap = cv2.VideoCapture(0)  # Open USB camera (adjust index if needed)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("Error: Could not open camera.")
        return

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to capture frame.")
            break

        process_frame(frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# Process video frames for pupil detection
def process_video(video_path):
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video.")
        return

    debug_mode_on = False
    sums = np.zeros(6)
    count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = process_frame(frame)
        times = results[1:]
        sums += times
        count += 1
    avgs = sums / count
    print(avgs)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    process_video("/home/pi/EyeTracker/eye_test.mp4")
